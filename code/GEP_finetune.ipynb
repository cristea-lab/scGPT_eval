{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEP \n",
    "Finetune the model with the GEP objective using PDAC cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/bash: /homes8/runzi/.conda/envs/scgpt/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "from einops import rearrange # for attention\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scgpt as scg\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt.model import TransformerModel\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch, random_mask_value\n",
    "from scgpt.loss import masked_mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(# data processing\n",
    "gene_col = 'gene',\n",
    "label_col = None,\n",
    "data_is_raw = False,\n",
    "filter_gene_by_counts = False,\n",
    "input_layer_key = 'X_binned',\n",
    "max_seq_len = 3001, # changed \n",
    "batch_size = 32, # training setup\n",
    "\n",
    "# model/training only configs\n",
    "domain_spec_batchnorm = 'batchnorm',\n",
    "input_emb_style = \"continuous\",\n",
    "cell_emb_style = \"cls\",\n",
    "n_input_bins = 51,\n",
    "mvc_decoder_style  = \"inner product\",\n",
    "ecs_threshold = 0.0 ,\n",
    "explicit_zero_prob = False,\n",
    "use_fast_transformer = True,\n",
    "fast_transformer_backend = \"flash\",\n",
    "pre_norm = False,\n",
    "\n",
    "n_layers_cls = 3,\n",
    "nhead = 8,\n",
    "embsize = 512,\n",
    "d_hid = 512,\n",
    "nlayers = 12,\n",
    "dropout = 0.2,\n",
    "\n",
    "lr = 1e-4,\n",
    "amp  = True,\n",
    "schedule_ratio=0.9,\n",
    "save_eval_interval=5,\n",
    "log_interval = 100,\n",
    "schedule_interval = 1,\n",
    "\n",
    "ADV = False,\n",
    "MLM = True, # for masked prediction training\n",
    "MVC = False,\n",
    "CLS = False,\n",
    "DAB = False,\n",
    "CCE = False,\n",
    "ECS = False,\n",
    "do_sample_in_train = False,\n",
    "INPUT_BATCH_LABELS = False,\n",
    "num_batch_labels = None,\n",
    "\n",
    "epochs = 15,\n",
    "\n",
    "# model and data processing\n",
    "n_bins = 51,\n",
    "include_zero_gene = False, # tokenization, but affects model's setup/behavior\n",
    "pad_token = '<pad>',\n",
    "mask_value = -1,\n",
    "pad_value = -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/cristealab/rtan/scGPT/VDR/data')\n",
    "model_dir = Path('/cristealab/rtan/scGPT/models/whole_human')\n",
    "save_dir = Path('/cristealab/rtan/scGPT/VDR/save')\n",
    "pancancer_dir = Path('/cristealab/rtan/scGPT/models/pan_cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VDR = sc.read(data_dir/'VDR.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDAC = VDR[VDR.obs.celltype=='PDAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 samples with more than 1000 PDAC cells\n",
    "sum(PDAC.obs.groupby(['patientID']).size()>1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = PDAC.obs.groupby(['patientID']).size().index[PDAC.obs.groupby(['patientID']).size()>1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDAC = PDAC[PDAC.obs.patientID.isin(pids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDAC.var = pd.read_csv(data_dir/'PDAC_hvgs.cvs', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match 24285/36601 genes in vocabulary of size 60697.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21633, 3000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter genes by vocab\n",
    "vocab_file = model_dir / \"vocab.json\"\n",
    "vocab = GeneVocab.from_file(vocab_file)\n",
    "\n",
    "PDAC.var[\"id_in_vocab\"] = [1 if gene in vocab else -1 for gene in PDAC.var[params['gene_col']]]\n",
    "\n",
    "gene_ids_in_vocab = np.array(PDAC.var[\"id_in_vocab\"])\n",
    "print(\n",
    "  f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n",
    "  f\"in vocabulary of size {len(vocab)}.\"\n",
    ")\n",
    "PDAC = PDAC[:, PDAC.var[\"id_in_vocab\"] >= 0]\n",
    "\n",
    "# keep top 3000 hvgs\n",
    "hvgs_index = PDAC.var.nlargest(3000, 'variances_norm').index\n",
    "PDAC = PDAC[:, hvgs_index]\n",
    "PDAC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning\n",
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=params['filter_gene_by_counts'],  # step 1\n",
    "    filter_cell_by_counts=False,  # step 2\n",
    "    normalize_total=False,  # 3. whether to normalize the raw data and to what sum\n",
    "    # result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=params['data_is_raw'],  # 4. whether to log1p the normalized data\n",
    "    # result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=False,  # 5. whether to subset the raw data to highly variable genes\n",
    "    # hvg_flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    binning=params['n_bins'],  # 6. whether to bin the raw data and to what number of bins\n",
    "    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Filtering cells by counts ...\n",
      "scGPT - INFO - Binning data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes8/runzi/.conda/envs/scgpt/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:137: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['n_counts'] = number\n"
     ]
    }
   ],
   "source": [
    "preprocessor(PDAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes8/runzi/.conda/envs/scgpt/lib/python3.8/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    }
   ],
   "source": [
    "# keep 1000 cells for each\n",
    "def split(adata, cols, numbers, seed):\n",
    "    adata_obs = adata.obs[cols]\n",
    "    adata_obs.loc[:,'row'] = range(0,adata.n_obs)\n",
    "    selection = adata_obs.groupby(cols).size()\n",
    "    selected_indices = []\n",
    "    for index in range(len(numbers)):\n",
    "        df = adata_obs[(adata_obs[cols]==selection.index[index]).all(axis=1)]\n",
    "        np.random.seed(123)\n",
    "        selected_indices += df['row'][np.random.choice(df.shape[0], numbers[index], replace=False)].tolist()\n",
    "    selected_indices.sort()\n",
    "\n",
    "    return adata[selected_indices]\n",
    "subPDAC = split(PDAC, ['patientID'], [1000]*6, 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function which receives adata and gives data_pt\n",
    "def adata_to_pt(adata, gene_col='gene', layer_key='X_binned',include_zero = False, CLS = False):\n",
    "    '''\n",
    "    from adata to pt\n",
    "    layer_key: need to consider 'X'\n",
    "    '''\n",
    "    all_counts = adata.layers[layer_key]\n",
    "    genes = adata.var[gene_col].tolist()\n",
    "    gene_ids = np.array(vocab(genes), dtype=int)\n",
    "    max_seq_len = max(np.sum(adata.layers[layer_key]>0, axis = 1))+1\n",
    "\n",
    "    tokenized_all = tokenize_and_pad_batch(\n",
    "        all_counts,\n",
    "        gene_ids,\n",
    "        max_len=max_seq_len,\n",
    "        vocab=vocab,\n",
    "        pad_token=params['pad_token'],\n",
    "        pad_value=params['pad_value'],\n",
    "        append_cls=True,  # append <cls> token at the beginning\n",
    "        include_zero_gene=include_zero,\n",
    "    )\n",
    "    tokenized_all['values'] = torch.tensor(tokenized_all['values'], dtype = torch.float)\n",
    "    if CLS:\n",
    "        tokenized_all['label_ids'] = torch.from_numpy(np.array(adata.obs.label_id)).long()\n",
    "    pt = {\n",
    "        \"gene_ids\": tokenized_all['genes'],\n",
    "        \"values\": tokenized_all['values'],\n",
    "    }\n",
    "    if CLS: \n",
    "        pt[\"labels\"] = tokenized_all['label_ids'],\n",
    "    return pt\n",
    "\n",
    "def mask(data_pt, mask_ratio=0):\n",
    "    masked_values = random_mask_value(\n",
    "    data_pt[\"values\"],\n",
    "    mask_ratio=mask_ratio,\n",
    "    mask_value=-1,\n",
    "    pad_value=-2,\n",
    "    )\n",
    "    data_pt.update({'masked_values':masked_values})\n",
    "    return data_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare pt\n",
    "train_data, test_data = train_test_split(subPDAC, test_size= 0.2, stratify=subPDAC.obs.patientID, shuffle=True, random_state=123)\n",
    "train_data, valid_data = train_test_split(train_data, test_size= 0.25, stratify=train_data.obs.patientID, shuffle=True, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 3000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subPDAC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_990053/3624361991.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokenized_all['values'] = torch.tensor(tokenized_all['values'], dtype = torch.float)\n"
     ]
    }
   ],
   "source": [
    "# use 1000 cells for training\n",
    "train_pt = adata_to_pt(subPDAC)\n",
    "train_pt = mask(train_pt, mask_ratio = 0.4)\n",
    "valid_pt = adata_to_pt(valid_data)\n",
    "valid_pt = mask(valid_pt, mask_ratio = 0.4)\n",
    "test_pt = adata_to_pt(test_data)\n",
    "test_pt = mask(test_pt, mask_ratio = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data[\"gene_ids\"].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.data.items()}\n",
    "    \n",
    "\n",
    "# data_loader\n",
    "def prepare_dataloader(\n",
    "    data_pt,\n",
    "    batch_size: int,\n",
    "    shuffle: bool = True,\n",
    "    intra_domain_shuffle: bool = False,\n",
    "    drop_last: bool = False,\n",
    "    num_workers: int = 0,\n",
    ") -> DataLoader:\n",
    "    if num_workers == 0:\n",
    "        num_workers = min(len(os.sched_getaffinity(0)), batch_size // 2)\n",
    "\n",
    "    dataset = SeqDataset(data_pt)\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using simple batchnorm instead of domain specific batchnorm\n",
      "Loading params encoder.embedding.weight with shape torch.Size([60697, 512])\n",
      "Loading params encoder.enc_norm.weight with shape torch.Size([512])\n",
      "Loading params encoder.enc_norm.bias with shape torch.Size([512])\n",
      "Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])\n",
      "Loading params value_encoder.linear1.bias with shape torch.Size([512])\n",
      "Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params value_encoder.linear2.bias with shape torch.Size([512])\n",
      "Loading params value_encoder.norm.weight with shape torch.Size([512])\n",
      "Loading params value_encoder.norm.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "Loading params transformer_encoder.layers.0.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "Loading params transformer_encoder.layers.1.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "Loading params transformer_encoder.layers.2.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "Loading params transformer_encoder.layers.3.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "Loading params transformer_encoder.layers.4.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "Loading params transformer_encoder.layers.5.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "Loading params transformer_encoder.layers.6.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "Loading params transformer_encoder.layers.7.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "Loading params transformer_encoder.layers.8.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "Loading params transformer_encoder.layers.9.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "Loading params transformer_encoder.layers.10.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.self_attn.Wqkv.weight with shape torch.Size([1536, 512])\n",
      "Loading params transformer_encoder.layers.11.self_attn.Wqkv.bias with shape torch.Size([1536])\n",
      "Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])\n",
      "Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])\n",
      "Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])\n",
      "Loading params decoder.fc.0.weight with shape torch.Size([512, 512])\n",
      "Loading params decoder.fc.0.bias with shape torch.Size([512])\n",
      "Loading params decoder.fc.2.weight with shape torch.Size([512, 512])\n",
      "Loading params decoder.fc.2.bias with shape torch.Size([512])\n",
      "Loading params decoder.fc.4.weight with shape torch.Size([1, 512])\n",
      "Loading params decoder.fc.4.bias with shape torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "# pretrained model\n",
    "model_file = model_dir / \"best_model.pt\"\n",
    "ntokens = len(vocab)  # size of vocabulary\n",
    "model = TransformerModel(\n",
    "    len(vocab),\n",
    "    params['embsize'],\n",
    "    params['nhead'],\n",
    "    params['d_hid'],\n",
    "    params['nlayers'],\n",
    "    vocab=vocab,\n",
    "    pad_token=params['pad_token'],\n",
    "    pad_value=params['pad_value'],\n",
    "    domain_spec_batchnorm=params['domain_spec_batchnorm'],\n",
    "    n_input_bins=params['n_input_bins'],\n",
    "    use_fast_transformer=params['use_fast_transformer'],\n",
    "    pre_norm=params['pre_norm'],\n",
    ")\n",
    "# to avoid error since batch is not present in input data\n",
    "model.domain_spec_batchnorm=False\n",
    "# load parameters\n",
    "if True:\n",
    "        # only load params that are in the model and match the size\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = torch.load(model_file)\n",
    "        pretrained_dict = {\n",
    "            k: v\n",
    "            for k, v in pretrained_dict.items()\n",
    "            if k in model_dict and v.shape == model_dict[k].shape\n",
    "        }\n",
    "        for k, v in pretrained_dict.items():\n",
    "            print(f\"Loading params {k} with shape {v.shape}\")\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for comparing before/after fine-tuning\n",
    "pretrained = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = masked_mse_loss\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_dab = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=params['lr'], eps=1e-4 if params['amp'] else 1e-8\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, params['schedule_interval'], gamma=params['schedule_ratio']\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=params['amp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, loader: DataLoader) -> None:\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    (\n",
    "        total_loss,\n",
    "        total_mse,\n",
    "    ) = (0.0, 0.0)\n",
    "    total_error = 0.0 # report multiple loss and error\n",
    "    # error is 1-accuracy for classification prediction in this task\n",
    "    start_time = time.time()\n",
    "\n",
    "    num_batches = len(loader)\n",
    "    log_interval = np.floor(num_batches/3)\n",
    "    for batch, batch_data in enumerate(loader):\n",
    "        input_gene_ids = batch_data[\"gene_ids\"].to(device)\n",
    "        input_values = batch_data[\"masked_values\"].to(device)\n",
    "        target_values = batch_data[\"values\"].to(device)\n",
    "        # arm_labels = batch_data[\"labels\"].to(device)\n",
    "\n",
    "        src_key_padding_mask = input_gene_ids.eq(vocab[params['pad_token']])\n",
    "        with torch.cuda.amp.autocast(enabled=params['amp']):\n",
    "            output_dict = model(\n",
    "                input_gene_ids,\n",
    "                input_values,\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                batch_labels=None,\n",
    "                CLS=params['CLS'],\n",
    "                CCE=params['CCE'],\n",
    "                MVC=params['MVC'],\n",
    "                ECS=params['ECS'],\n",
    "                do_sample=params['do_sample_in_train'],\n",
    "                #generative_training=False\n",
    "            )\n",
    "\n",
    "            masked_positions = input_values.eq(params['mask_value'])  # the postions to predict\n",
    "\n",
    "            # loss for this batch\n",
    "            loss = 0.0\n",
    "            # keep losses for this batch\n",
    "            metrics_to_log = {}\n",
    "            if params['MLM']:\n",
    "                loss_mse = criterion(\n",
    "                    output_dict[\"mlm_output\"], target_values, masked_positions\n",
    "                )\n",
    "                loss = loss + loss_mse\n",
    "                metrics_to_log = {\"train/mse\": loss_mse.item()}\n",
    "            \n",
    "            \n",
    "        # after calculating the results within the batch, update \n",
    "        model.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        \n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.filterwarnings(\"always\")\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(),\n",
    "                1.0,\n",
    "                error_if_nonfinite=False if scaler.is_enabled() else True,\n",
    "            )\n",
    "            if len(w) > 0:\n",
    "                print(\n",
    "                    f\"Found infinite gradient. This may be caused by the gradient \"\n",
    "                    f\"scaler. The current scale is {scaler.get_scale()}. This warning \"\n",
    "                    \"can be ignored if no longer occurs after autoscaling of the scaler.\"\n",
    "                )\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    " \n",
    "        #wandb.log(metrics_to_log)\n",
    "        # after some batches, report progress: total_loss etc. are used to calculate mean performance of those batches\n",
    "        total_loss += loss.item()\n",
    "        total_mse += loss_mse.item() if params['MLM'] else \"\"\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            cur_mse = total_mse / log_interval\n",
    "            # ppl = math.exp(cur_loss)\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:3d}/{num_batches:3d} batches | \"\n",
    "                f\"lr {lr:05.4f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | \"\n",
    "                + (f\"mse {cur_mse:5.2f} | \" if params['MLM'] else \"\")\n",
    "            )\n",
    "            total_loss = 0\n",
    "            total_mse = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, loader: DataLoader, return_raw: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the evaluation data.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_num = 0\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_data in loader:\n",
    "            input_gene_ids = batch_data[\"gene_ids\"].to(device)\n",
    "            input_values = batch_data[\"masked_values\"].to(device)\n",
    "            target_values = batch_data[\"values\"].to(device)\n",
    "            masked_positions = input_values.eq(params['mask_value'])\n",
    "\n",
    "            src_key_padding_mask = input_gene_ids.eq(vocab[params['pad_token']])\n",
    "            with torch.cuda.amp.autocast(enabled=params['amp']):\n",
    "                output_dict = model(\n",
    "                input_gene_ids,\n",
    "                input_values,\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                batch_labels=None,\n",
    "                CLS=params['CLS'],\n",
    "                CCE=params['CCE'],\n",
    "                MVC=params['MVC'],\n",
    "                ECS=params['ECS'],\n",
    "                do_sample=params['do_sample_in_train'],\n",
    "                #generative_training=False\n",
    "            )\n",
    "                output_values = output_dict[\"mlm_output\"]\n",
    "                loss = criterion(\n",
    "                    output_values, target_values, masked_positions\n",
    "                )\n",
    "\n",
    "\n",
    "            total_loss += loss.item() * len(input_gene_ids)\n",
    "            total_num += len(input_gene_ids)\n",
    "    '''\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"valid/mse\": total_loss / total_num,\n",
    "            \"valid/err\": total_error / total_num,\n",
    "            \"valid/dab\": total_dab / total_num,\n",
    "            \"valid/sum_mse_dab\": (total_loss + dab_weight * total_dab) / total_num,\n",
    "            \"epoch\": epoch,\n",
    "        },\n",
    "    )'''\n",
    "\n",
    "    '''if return_raw:\n",
    "        return np.concatenate(predictions, axis=0)'''\n",
    "\n",
    "    return total_loss / total_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  62/188 batches | lr 0.0001 | ms/batch 286.76 | loss 213.09 | mse 213.09 | \n",
      "| epoch   1 | 124/188 batches | lr 0.0001 | ms/batch 124.03 | loss 196.07 | mse 196.07 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 | 186/188 batches | lr 0.0001 | ms/batch 125.89 | loss 184.59 | mse 184.59 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 38.62s | valid loss/mse 183.5351\n",
      "-----------------------------------------------------------------------------------------\n",
      "Best model with score 183.5351\n",
      "| epoch   2 |  62/188 batches | lr 0.0001 | ms/batch 180.93 | loss 183.53 | mse 183.53 | \n",
      "| epoch   2 | 124/188 batches | lr 0.0001 | ms/batch 125.53 | loss 184.83 | mse 184.83 | \n",
      "| epoch   2 | 186/188 batches | lr 0.0001 | ms/batch 126.57 | loss 174.32 | mse 174.32 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 32.42s | valid loss/mse 170.4101\n",
      "-----------------------------------------------------------------------------------------\n",
      "Best model with score 170.4101\n",
      "| epoch   3 |  62/188 batches | lr 0.0001 | ms/batch 181.13 | loss 176.86 | mse 176.86 | \n",
      "| epoch   3 | 124/188 batches | lr 0.0001 | ms/batch 126.05 | loss 181.59 | mse 181.59 | \n",
      "| epoch   3 | 186/188 batches | lr 0.0001 | ms/batch 133.93 | loss 169.86 | mse 169.86 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 33.32s | valid loss/mse 170.0879\n",
      "-----------------------------------------------------------------------------------------\n",
      "Best model with score 170.0879\n",
      "| epoch   4 |  62/188 batches | lr 0.0001 | ms/batch 199.62 | loss 172.81 | mse 172.81 | \n",
      "| epoch   4 | 124/188 batches | lr 0.0001 | ms/batch 144.31 | loss 178.28 | mse 178.28 | \n",
      "| epoch   4 | 186/188 batches | lr 0.0001 | ms/batch 141.17 | loss 167.23 | mse 167.23 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 36.06s | valid loss/mse 167.3659\n",
      "-----------------------------------------------------------------------------------------\n",
      "Best model with score 167.3659\n",
      "| epoch   5 |  62/188 batches | lr 0.0001 | ms/batch 190.10 | loss 170.34 | mse 170.34 | \n",
      "| epoch   5 | 124/188 batches | lr 0.0001 | ms/batch 126.65 | loss 175.98 | mse 175.98 | \n",
      "| epoch   5 | 186/188 batches | lr 0.0001 | ms/batch 127.67 | loss 164.91 | mse 164.91 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 33.59s | valid loss/mse 168.0412\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |  62/188 batches | lr 0.0001 | ms/batch 187.33 | loss 168.85 | mse 168.85 | \n",
      "| epoch   6 | 124/188 batches | lr 0.0001 | ms/batch 127.73 | loss 174.38 | mse 174.38 | \n",
      "| epoch   6 | 186/188 batches | lr 0.0001 | ms/batch 127.23 | loss 163.00 | mse 163.00 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 33.51s | valid loss/mse 169.1544\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |  62/188 batches | lr 0.0001 | ms/batch 202.71 | loss 167.26 | mse 167.26 | \n",
      "| epoch   7 | 124/188 batches | lr 0.0001 | ms/batch 126.91 | loss 172.91 | mse 172.91 | \n",
      "| epoch   7 | 186/188 batches | lr 0.0001 | ms/batch 126.96 | loss 161.92 | mse 161.92 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 34.28s | valid loss/mse 170.7034\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |  62/188 batches | lr 0.0000 | ms/batch 192.10 | loss 166.29 | mse 166.29 | \n",
      "| epoch   8 | 124/188 batches | lr 0.0000 | ms/batch 131.56 | loss 171.98 | mse 171.98 | \n",
      "| epoch   8 | 186/188 batches | lr 0.0000 | ms/batch 131.77 | loss 161.01 | mse 161.01 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 34.48s | valid loss/mse 170.1784\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |  62/188 batches | lr 0.0000 | ms/batch 195.30 | loss 165.17 | mse 165.17 | \n",
      "| epoch   9 | 124/188 batches | lr 0.0000 | ms/batch 139.10 | loss 171.11 | mse 171.11 | \n",
      "| epoch   9 | 186/188 batches | lr 0.0000 | ms/batch 135.63 | loss 159.95 | mse 159.95 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 35.75s | valid loss/mse 170.3285\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |  62/188 batches | lr 0.0000 | ms/batch 216.85 | loss 164.65 | mse 164.65 | \n",
      "| epoch  10 | 124/188 batches | lr 0.0000 | ms/batch 130.03 | loss 169.89 | mse 169.89 | \n",
      "| epoch  10 | 186/188 batches | lr 0.0000 | ms/batch 135.47 | loss 159.20 | mse 159.20 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 36.23s | valid loss/mse 168.9786\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |  62/188 batches | lr 0.0000 | ms/batch 184.19 | loss 163.96 | mse 163.96 | \n",
      "| epoch  11 | 124/188 batches | lr 0.0000 | ms/batch 125.67 | loss 169.51 | mse 169.51 | \n",
      "| epoch  11 | 186/188 batches | lr 0.0000 | ms/batch 133.17 | loss 158.14 | mse 158.14 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 33.46s | valid loss/mse 171.4809\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |  62/188 batches | lr 0.0000 | ms/batch 192.04 | loss 163.26 | mse 163.26 | \n",
      "| epoch  12 | 124/188 batches | lr 0.0000 | ms/batch 131.59 | loss 168.72 | mse 168.72 | \n",
      "| epoch  12 | 186/188 batches | lr 0.0000 | ms/batch 131.39 | loss 157.21 | mse 157.21 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 34.13s | valid loss/mse 171.4090\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |  62/188 batches | lr 0.0000 | ms/batch 193.82 | loss 162.74 | mse 162.74 | \n",
      "| epoch  13 | 124/188 batches | lr 0.0000 | ms/batch 126.50 | loss 167.89 | mse 167.89 | \n",
      "| epoch  13 | 186/188 batches | lr 0.0000 | ms/batch 132.98 | loss 156.54 | mse 156.54 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 35.24s | valid loss/mse 172.0956\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |  62/188 batches | lr 0.0000 | ms/batch 216.19 | loss 162.35 | mse 162.35 | \n",
      "| epoch  14 | 124/188 batches | lr 0.0000 | ms/batch 128.29 | loss 167.60 | mse 167.60 | \n",
      "| epoch  14 | 186/188 batches | lr 0.0000 | ms/batch 126.51 | loss 155.92 | mse 155.92 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 35.44s | valid loss/mse 171.5882\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |  62/188 batches | lr 0.0000 | ms/batch 213.64 | loss 161.81 | mse 161.81 | \n",
      "| epoch  15 | 124/188 batches | lr 0.0000 | ms/batch 144.83 | loss 166.83 | mse 166.83 | \n",
      "| epoch  15 | 186/188 batches | lr 0.0000 | ms/batch 131.86 | loss 155.53 | mse 155.53 | \n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 36.48s | valid loss/mse 169.4464\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "best_avg_bio = 0.0\n",
    "best_model = None\n",
    "\n",
    "model.to(device)\n",
    "for epoch in range(1, params['epochs'] + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_loader = prepare_dataloader(\n",
    "        train_pt,\n",
    "        batch_size=params['batch_size'],\n",
    "        shuffle=False,\n",
    "        intra_domain_shuffle=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    valid_loader = prepare_dataloader(\n",
    "        valid_pt,\n",
    "        batch_size=params['batch_size'],\n",
    "        shuffle=False,\n",
    "        intra_domain_shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    if True:\n",
    "        train(\n",
    "            model,\n",
    "            loader=train_loader,\n",
    "        )\n",
    "    val_loss = evaluate(\n",
    "        model,\n",
    "        loader=valid_loader,\n",
    "    )\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    print(\"-\" * 89)\n",
    "    print(\n",
    "        f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "        f\"valid loss/mse {val_loss:5.4f}\"\n",
    "    )\n",
    "    print(\"-\" * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_model_epoch = epoch\n",
    "        print(f\"Best model with score {best_val_loss:5.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    # if (epoch - best_model_epoch)>3: break # early break\n",
    "# 15 epochs, 6m32s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GEP(model, data_pt, masked_prediction = False):\n",
    "    if masked_prediction: print('Return prediction values for masked positions')\n",
    "    else: print('Return predictions for all positions')\n",
    "    data = SeqDataset(data_pt)\n",
    "    # no shuffle\n",
    "    loader = DataLoader(\n",
    "            data,\n",
    "            batch_size=params['batch_size'],\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            num_workers=min(len(os.sched_getaffinity(0)), params['batch_size'] // 2)\n",
    "        )\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    predictions = []\n",
    "    true_values = []\n",
    "    total_loss = 0\n",
    "    total_num = len(data_pt['gene_ids'])\n",
    "    # device = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        for batch, batch_data in enumerate(loader):\n",
    "            input_gene_ids = batch_data[\"gene_ids\"].to(device)\n",
    "            input_values = batch_data[\"masked_values\"].to(device) if masked_prediction else batch_data[\"values\"].to(device)\n",
    "            target_values = batch_data[\"values\"].to(device)\n",
    "            batch_len = input_gene_ids.shape[0]\n",
    "\n",
    "            src_key_padding_mask = input_gene_ids.eq(vocab[params['pad_token']]).to(device)\n",
    "            with torch.cuda.amp.autocast(enabled=True):\n",
    "                output_dict = model(\n",
    "                    input_gene_ids,\n",
    "                    input_values,\n",
    "                    src_key_padding_mask=src_key_padding_mask,\n",
    "                    batch_labels=None,\n",
    "                    CLS=False,  # evaluation does not need CLS or CCE\n",
    "                    CCE=False,\n",
    "                    MVC=False,\n",
    "                    ECS=False,\n",
    "                    do_sample=False,\n",
    "                    #generative_training = False,\n",
    "                )\n",
    "                masked_positions = input_values.eq(params['mask_value'])\n",
    "                total_loss += (criterion(output_dict[\"mlm_output\"], target_values,masked_positions)).item()*len(input_gene_ids)\n",
    "                for i in range(batch_len): # get results for each cell\n",
    "                    if masked_prediction:\n",
    "                        masked_positions = input_values[i].eq(params['mask_value']).to('cpu')\n",
    "                        output_values = output_dict[\"mlm_output\"][i].to('cpu')[masked_positions]\n",
    "                        output_target_values = target_values[i].to('cpu')[masked_positions]\n",
    "                    else:\n",
    "                        nonzero_positions = (input_values[i]>0).to('cpu')\n",
    "                        output_values = output_dict[\"mlm_output\"][i].to('cpu')[nonzero_positions]\n",
    "                        output_target_values = target_values[i].to('cpu')[nonzero_positions]\n",
    "                    \n",
    "\n",
    "                    predictions.append(output_values.tolist())\n",
    "                    true_values.append(output_target_values.tolist())\n",
    "                \n",
    "    mse = total_loss/total_num\n",
    "    return predictions, true_values, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show fine-tuned and pre-trained for predicting values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return prediction values for masked positions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "167.53921447753908"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 40% masked\n",
    "results = GEP(best_model, test_pt, masked_prediction=True)\n",
    "results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre = []\n",
    "for i in results[0]: pre=pre+i\n",
    "true = []\n",
    "for i in results[1]: true = true+i\n",
    "data = pd.DataFrame({'X': true, 'Y': pre})\n",
    "# Create a boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='X', y='Y', data=data, showfliers=False, color='skyblue')\n",
    "\n",
    "# Alternatively, create a violin plot\n",
    "# sns.violinplot(x='X', y='Y', data=data)\n",
    "\n",
    "plt.title('Expression prediction')\n",
    "plt.xlabel('Input bin values')\n",
    "plt.ylabel('Predicted bin values')\n",
    "selected_labels = np.arange(0,50, 5 )\n",
    "plt.xticks(ticks=selected_labels, labels=selected_labels)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
